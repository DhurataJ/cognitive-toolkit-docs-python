### YamlMime:PythonClass
uid: cntk.contrib.deeprl.agent.qlearning.QLearning
name: QLearning
fullName: cntk.contrib.deeprl.agent.qlearning.QLearning
module: cntk.contrib.deeprl.agent.qlearning
inheritances:
- cntk.contrib.deeprl.agent.agent.AgentBaseClass
summary: 'Q-learning agent.


  Including:

  - DQN [https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)

  - Prioritized Experience Replay [https://arxiv.org/pdf/1511.05952.pdf](https://arxiv.org/pdf/1511.05952.pdf)

  - Dueling Network [https://arxiv.org/pdf/1511.06581.pdf](https://arxiv.org/pdf/1511.06581.pdf)

  - Double Q Learning [https://arxiv.org/pdf/1509.06461.pdf](https://arxiv.org/pdf/1509.06461.pdf)'
constructor:
  syntax: QLearning(config_filename, o_space, a_space)
methods:
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.end
  name: end
  summary: Last observed reward/state of the episode (which then terminates).
  signature: end(reward, next_state)
  parameters:
  - name: reward
    description: amount of reward returned after previous action.
    isRequired: true
    types:
    - <xref:float>
  - name: next_state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.enter_evaluation
  name: enter_evaluation
  summary: Setup before evaluation.
  signature: enter_evaluation()
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.save
  name: save
  summary: Save model to file.
  signature: save(filename)
  parameters:
  - name: filename
    isRequired: true
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.save_parameter_settings
  name: save_parameter_settings
  summary: Save parameter settings to file.
  signature: save_parameter_settings(filename)
  parameters:
  - name: filename
    isRequired: true
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.set_as_best_model
  name: set_as_best_model
  summary: Copy current model to best model.
  signature: set_as_best_model()
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.start
  name: start
  summary: Start a new episode.
  signature: start(state)
  parameters:
  - name: state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
  return:
    description: 'action choosen by agent.

      debug_info (dict): auxiliary diagnostic information.'
    types:
    - <xref:action >(<xref:int>)
- uid: cntk.contrib.deeprl.agent.qlearning.QLearning.step
  name: step
  summary: Observe one transition and choose an action.
  signature: step(reward, next_state)
  parameters:
  - name: reward
    description: amount of reward returned after previous action.
    isRequired: true
    types:
    - <xref:float>
  - name: next_state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
  return:
    description: 'action choosen by agent.

      debug_info (dict): auxiliary diagnostic information.'
    types:
    - <xref:action >(<xref:int>)

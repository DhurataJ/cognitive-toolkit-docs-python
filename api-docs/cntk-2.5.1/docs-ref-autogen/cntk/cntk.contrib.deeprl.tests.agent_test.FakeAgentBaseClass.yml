### YamlMime:PythonClass
uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass
name: FakeAgentBaseClass
fullName: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass
module: cntk.contrib.deeprl.tests.agent_test
inheritances:
- cntk.contrib.deeprl.agent.agent.AgentBaseClass
summary: Subclass AgentBaseClass for unittest.
constructor:
  syntax: FakeAgentBaseClass(o_space, a_space)
methods:
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.end
  name: end
  summary: Last observed reward/state of the episode (which then terminates).
  signature: end(reward, next_state)
  parameters:
  - name: reward
    description: amount of reward returned after previous action.
    isRequired: true
    types:
    - <xref:float>
  - name: next_state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.save
  name: save
  summary: Save model to file.
  signature: save(filename)
  parameters:
  - name: filename
    isRequired: true
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.save_parameter_settings
  name: save_parameter_settings
  summary: Save parameter settings to file.
  signature: save_parameter_settings(filename)
  parameters:
  - name: filename
    isRequired: true
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.set_as_best_model
  name: set_as_best_model
  summary: Copy current model to best model.
  signature: set_as_best_model()
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.start
  name: start
  summary: Start a new episode.
  signature: start(state)
  parameters:
  - name: state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
  return:
    description: 'action choosen by agent.

      debug_info (dict): auxiliary diagnostic information.'
    types:
    - <xref:action >(<xref:int>)
- uid: cntk.contrib.deeprl.tests.agent_test.FakeAgentBaseClass.step
  name: step
  summary: Observe one transition and choose an action.
  signature: step(reward, next_state)
  parameters:
  - name: reward
    description: amount of reward returned after previous action.
    isRequired: true
    types:
    - <xref:float>
  - name: next_state
    description: observation provided by the environment.
    isRequired: true
    types:
    - <xref:object>
  return:
    description: 'action choosen by agent.

      debug_info (dict): auxiliary diagnostic information.'
    types:
    - <xref:action >(<xref:int>)

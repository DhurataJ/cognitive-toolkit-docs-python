### YamlMime:PythonPackage
uid: cntk.losses
name: losses
fullName: cntk.losses
summary: Loss functions.
type: import
functions:
- uid: cntk.losses.binary_cross_entropy
  name: binary_cross_entropy
  summary: Computes the binary cross entropy (aka logistic loss) between the `output`
    and `target`.
  signature: binary_cross_entropy(output, target, name='')
  parameters:
  - name: output
    description: the computed posterior probability for a variable to be 1 from the
      network (typ. a `sigmoid`)
    isRequired: true
  - name: target
    description: ground-truth label, 0 or 1
    isRequired: true
  - name: name
    description: the name of the Function instance in the network
    isRequired: true
    types:
    - <xref:str>, <xref:optional>
  return:
    description: <xref:cntk.ops.functions.Function>
- uid: cntk.losses.cosine_distance
  name: cosine_distance
  summary: 'Computes the cosine distance between `x` and `y`:'
  signature: cosine_distance(x, y, name='')
  parameters:
  - name: x
    description: numpy array or any <xref:cntk.ops.functions.Function> that outputs
      a tensor
    isRequired: true
  - name: name
    description: the name of the Function instance in the network
    isRequired: true
    types:
    - <xref:str>, <xref:optional>
  return:
    description: <xref:cntk.ops.functions.Function>
  examples:
  - "\n```\n\n>>> a = np.asarray([-1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1]).reshape(3,2,2)\n\
    >>> b = np.asarray([1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1]).reshape(3,2,2)\n\
    >>> x = C.sequence.input_variable(shape=(2,))\n>>> y = C.sequence.input_variable(shape=(2,))\n\
    >>> np.round(C.cosine_distance(x,y).eval({x:a,y:b}),5)\narray([[-1.,  1.],\n \
    \      [ 1.,  0.],\n       [ 0., -1.]], dtype=float32)\n```\n"
- uid: cntk.losses.cosine_distance_with_negative_samples
  name: cosine_distance_with_negative_samples
  summary: 'Given minibatches for `x` and `y`, this function computes for each element
    in *x* the cosine distance between

    it and the corresponding *y* and additionally the cosine distance between `x`
    and some other elements of `y`

    (referred to a negative samples). The `x` and `y` pairs are samples often derived

    from embeddings of textual data, though the function can be used for any form
    of numeric encodings.

    When using this function to compute textual similarity, `x` represents search
    query term embedding

    and `y` represents a document embedding. The negative samples are formed on the
    fly by shifting

    the right side (`y`). The `shift` indicates how many samples in `y` one should
    shift while

    forming each negative sample pair. It is often chosen to be 1. As the name suggests

    `num_negative_samples` indicates how many negative samples one would want to generate.'
  signature: cosine_distance_with_negative_samples(x, y, shift, num_negative_samples,
    name='')
  parameters:
  - name: x
    description: numpy array or any <xref:cntk.ops.functions.Function> that outputs
      a tensor
    isRequired: true
  - name: y
    description: numpy array or any <xref:cntk.ops.functions.Function> that outputs
      a tensor
    isRequired: true
  - name: shift
    description: non-zero positive integer representing number of shift to generate
      a negative sample
    isRequired: true
  - name: num_negative_samples
    description: number of negative samples to generate, a non-zero positive integer
    isRequired: true
  - name: name
    description: the name of the Function instance in the network
    isRequired: true
    types:
    - <xref:str>, <xref:optional>
  return:
    description: <xref:cntk.ops.functions.Function>
  examples:
  - "\n```\n\n>>> qry = np.asarray([1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\
    \ dtype=np.float32).reshape(3, 1, 4)\n>>> doc = np.asarray([1., 1., 0., 0., 0.,\
    \ 1., 1., 0., 0., 0., 1., 1.], dtype=np.float32).reshape(3, 1, 4)\n>>> x = C.sequence.input_variable(shape=(4,))\n\
    >>> y = C.sequence.input_variable(shape=(4,))\n>>> model = C.cosine_distance_with_negative_samples(x,\
    \ y, shift=1, num_negative_samples=2)\n>>> np.round(model.eval({x: qry, y: doc}),\
    \ decimals=4)\narray([[[ 1. ,  0.5,  0. ]],\n\n       [[ 1. ,  0.5,  0.5]],\n\n\
    \       [[ 1. ,  0. ,  0.5]]], dtype=float32)\n```\n"
- uid: cntk.losses.cross_entropy_with_softmax
  name: cross_entropy_with_softmax
  signature: cross_entropy_with_softmax(output_vector, target_vector, axis=-1, name='')
- uid: cntk.losses.fmeasure
  name: fmeasure
  signature: fmeasure(output, target, beta=1)
- uid: cntk.losses.hierarchical_softmax_layer
  name: hierarchical_softmax_layer
  signature: hierarchical_softmax_layer(input_var, label_index, label_dim, label_classes=None)
- uid: cntk.losses.lambda_rank
  name: lambda_rank
  signature: lambda_rank(output, gain, group, name='')
- uid: cntk.losses.lattice_sequence_with_softmax
  name: lattice_sequence_with_softmax
  signature: lattice_sequence_with_softmax(label, prediction, loglikelihood, lattice,
    symListPath, phonePath, stateListPath, transProbPath, latticeConfigPath='LatticeNode.config',
    hSmoothingWeight=0.95, frameDropThresh=1e-10, doReferenceAlign=False, seqGammarUsesMBR=False,
    seqGammarAMF=14.0, seqGammarLMF=14.0, seqGammarBMMIFactor=0.0, seqGammarWordPen=0.0,
    name='')
- uid: cntk.losses.nce_loss
  name: nce_loss
  signature: nce_loss(weights, biases, inputs, labels, noise_distribution, num_samples=32,
    allow_duplicates=True, seed=auto_select, name='')
- uid: cntk.losses.squared_error
  name: squared_error
  signature: squared_error(output, target, name='')
- uid: cntk.losses.weighted_binary_cross_entropy
  name: weighted_binary_cross_entropy
  signature: weighted_binary_cross_entropy(output, target, weight, name='')
packages:
- cntk.losses.tests
